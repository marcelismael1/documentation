#Kubernetes

https://linuxacademy.com/cp/courses/lesson/course/3515
# It is a container orchestrator tool that allow us to manage and scale containers easily

############################### building Kubernetes cluster ##################

# simple cluster consists of 3 node:
 ------			 --------        --------
|Master|		|Kub Node|		|Kub Node|
 ------			 --------        --------
 Docker			  Docker 	       Docker     # Container Engine
 Kubeadm          Kubeadm          Kubeadm    # Simplify cluster creation
 Kubelet          Kubelet          Kubelet    # An agent to manage the cluster
 Kubectl          Kubectl          Kubectl	  # Kubernetes command line
 Control 		                              # Controller for the Master Node
 ================================================================

-------------------------- INSTALL DOCKER on Ubuntu----------------------------
# get package key and add key to apt package manager
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

# Add docker repo 
sudo add-apt-repository \
   "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
   $(lsb_release -cs) \
   stable"
  
# When we add a new repo we update package listing
sudo apt-get update

# install docker version 18.06.1~ce~3-0~ubuntu for ubuntu
sudo apt-get install -y docker-ce=18.06.1~ce~3-0~ubuntu

# mark docker-ce package to remove it from auto upgrade list ( for full control)
sudo apt-mark hold docker-ce

-------------------------- INSTALL Kube tools on Ubuntu----------------------------
# Get k8 package key
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

# add k8 repo to repo list
cat << EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF
# update
sudo apt-get update

# install kube tools (MUST BE SAME VERSION)
sudo apt-get install -y kubelet=1.15.7-00 kubeadm=1.15.7-00 kubectl=1.15.7-00  

# hold the version to prevent auto update
sudo apt-mark hold kubelet kubeadm kubectl

-------------------------- bootstrap k8 cluster ----------------------------
#On the Kube master node, initialize the cluster:
### NOOOOTEEEEL: master should have 2 vCPUs
sudo kubeadm init --pod-network-cidr=10.244.0.0/16  # initialize the cluster it produce information to configure kubectl and add nodes to cluster

# When it is done, set up the local kubeconfig:
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# Verify that the cluster is responsive and that Kubectl is working:

kubectl version

#You should get Server Version as well as Client Version. It should look something like this:
#>>Client Version: version.Info{Major:"1", Minor:"12", GitVersion:"v1.12.2", GitCommit:"17c77c7898218073f14c8d573582e8d2313dc740", GitTreeState:"clean", BuildDate:"2018-10-24T06:54:59Z", GoVersion:"go1.10.4", Compiler:"gc", Platform:"linux/amd64"}
#>> Server Version: version.Info{Major:"1", Minor:"12", GitVersion:"v1.12.2", GitCommit:"17c77c7898218073f14c8d573582e8d2313dc740", GitTreeState:"clean", BuildDate:"2018-10-24T06:43:59Z", GoVersion:"go1.10.4", Compiler:"gc", Platform:"linux/amd64"}

# on the nodes
#The kubeadm init command should output a kubeadm join command containing a token and hash. Copy that command and run it with sudo on both worker nodes. It should look something like this:
sudo kubeadm join $some_ip:6443 --token $some_token --discovery-token-ca-cert-hash $some_hash

#Verify that all nodes have successfully joined the cluster:
kubectl get nodes

#You should see all three of your nodes listed. It should look something like this:
NAME                      STATUS     ROLES    AGE     VERSION
wboyd1c.mylabserver.com   NotReady   master   5m17s   v1.12.2
wboyd2c.mylabserver.com   NotReady   <none>   53s     v1.12.2
wboyd3c.mylabserver.com   NotReady   <none>   31s     v1.12.2
#Note:* The nodes are expected to have a STATUS of NotReady at this point.

----------------------------- Configure Network ---------------------------

# K8 support a lot of network pluggins and we can configure networking by a lot of ways
# we will use FLANNEL which is a network configuration pluggin.

# 1) run the below codes in each node
echo "net.bridge.bridge-nf-call-iptables=1" | sudo tee -a /etc/sysctl.conf # put the value "net.bridge.bridge-nf-call-iptables=1" in /etc/sysctl.conf
sudo sysctl -p  # run sysctl to take effect immediately

# 2) run the below comand on Master node ONLY
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml
# this will laod YAML file from the link (-f option) and configure the network using flannel configuration
# 3) we can check the network is running by using 
kubectl get nodes   # we can see that all nodes are ready
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
                    Kubernetes Cluster is READY
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

------------------------------ 'PODS' ----------------------------------------

# Pods are the basic block in K8
# a pod can contain more that one container Usually 1
# each pod have an ip from  K8 network (10.244.0.0/16) in our example
                    
# to create a pod
 kubectl create -f <podfile.yml>

 # the yml file looks something like this

 apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx

# to view the running pods

kubectl get pods
kubectl get pods -o wide  # more details


# view the pods that related to system 
kubectl get pods -n kube-system

# pods are seperated by name space and to use this we do
kubectl get pods --all-namespaces

# get details about a pod (inculding event list)
kubectl describe pod <pod_name>
kubectl describe pod nginx

# describe a pod running in a namespace
kubectl describe pod <pod_name> -n <namespace>

# NOTE:   we can get details about different K8 objects like services by describe

# to delete a pod

kubectl delete pod <pod_name>
kubectl delete pod nginx

------------------------------ 'Clustering and Nodes' -------------------
# previously we build a cluster and now we have a master and 2 worker nodes 
# the pods will run on worker nodes

# simple cluster consists of 3 node:
 ------			 --------        --------
|Master|		|.Worker.|		|.Worker.|
 ------			 --------        --------
 API			  Pod  	       	   Pod
 Control          Pod          	   Pod
 Panel

# get list of nodes
kubectl get nodes

# get node details
kubectl describe node $node_name

 ---------------------------------- 'Networking in Kubernetes' -------------------

 # K8 have all the pods connected to virtual network in a way that even if  pods are on different nodes 
 # they can communicate using the pods ip address

 # there are alot of plugins that can do that, and Flannel is one of them


# we can test that by creating several pods and try to excute some commands from one of them towards the others
# using thier ip 
# lets suppose we have busybox that can run ;'curl' and nginx pod

kubectl exec <pod_name> -- <command>

kubectl exec busybox -- curl <nginx_ip>

-------------------------------------' Kubernetes Architecture and Components ' ----------------
# if we ran  the below command I will get the list of pods that represent the system pods and components
kubectl get pods -n kube-system

# Core DNS , Dns for other nodes
coredns-5d4dd4b4db-7qdbc           node2   
coredns-5d4dd4b4db-8mr4n           node2   

# etcd is a pod that runs on the master and it porvides distributed sync data storage for the cluster
etcd-master1                       master1 

# API server .K8s API which is the primary interfaace for the cluster
kube-apiserver-master1             master1 

# Controller Manager- Bubdles several components into package
kube-controller-manager-master1    master1 

# This is the network plugin pod(one for each node)
kube-flannel-ds-amd64-4nrlt        node1   
kube-flannel-ds-amd64-52dns        master1 
kube-flannel-ds-amd64-kz8fx        node2   

# Proxy pod, once for each node, handles network communiction betwwen pods, ny setting routing firewall rules
kube-proxy-25j95                   node1   
kube-proxy-7cx4r                   master1 
kube-proxy-p2pv8                   node2   
	
# Master Scheduler , which Schedules the creation and deletion of pods
kube-scheduler-master1             master1 

############## ' kubelet'########
# Kublet is K8s engin the means that it is the component that works as the cbridge between docker and other components
# so it manages pods (this means it is not a pod) it runs as a process

sudo systemctl status kubelet


-------------------------------------------' Kubernetes Deployments' --------------------------------
# Deployments are a K8s object that represents a set of rules it is great for automating the deployment of pods with deployment you can
# specify a desired state in which you want your pods to be in and it is useful to in the below cases.

# >>> Scaling: you can specify the number of replicas and k8s will maintain this number
# >>> Rolling Updates: we can change the deplyment version to new image. the dyployment will gradually change the version of the images to new one
# >>> Self-Healing: if one pod was damaged the dyployment will automatically spin new one

# EXAMPLE

apiVersion: apps/v1
kind: Deployment    # object type
metadata:
  name: nginx-deployment
  labels:
    app: nginx    # label
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx       # replicas LABEL (important)
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.15.4
        ports:
        - containerPort: 80

 # in this deployment we have 2 replicas of nginx at it will maintain the number
kubectl get deployments  		# View all Deployments

kubectl describe deployment nginx-deployment		# get additional information about the deployment

kubectl delete deployment nginx-deployment			# will delete the deployment

# if we tried and deleted a pod and checked the pods again the same numnber of replicas will remain


------------------------------------------- ' Kubernetes Services' --------------------------------------------------
# K8s services are another component of kubernetes, it is very importantin deploying apps
# Since replication pods are ofter created and destroyed, services provide a way of communicating with a set of pods
# it creates a layer of communication with the pods, so you can communicate with service insead of the replicas

kind: Service    # object kind
apiVersion: v1
metadata:
  name: nginx-service  # name of service
spec:
  selector:            # what are the label of replicas to connect to
    app: nginx
  ports:
  - protocol: TCP		# protocol
    port: 80			# internal port (node port)
    targetPort: 80		# 
    nodePort: 30080		# exposed port
  type: nodePort   	    # type of service
 

kubectl create -f test_service.yml   # create a service

kubectl get svc                      # list services


NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
kubernetes      ClusterIP   10.96.0.1        <none>        443/TCP        4d19h				# Kubernetes cluster API service
nginx-service   NodePort    10.108.113.209   <none>        80:30080/TCP   10s				# newly added service

# now the cluster have nginx service on port 30080, when trying to communicate with any node of the cluster on 30080  arequest to nginx nodes will be sent to handle it

curl localhost:30080
 <nginx server response>

# Delete a service
kubectl delete svc nginx-service

 ---------------------------------------  ' Deploying the Robot Shop App ' -------------------------------------

 # to create a microservice application it is very easy with K8s. we will take the below example
git clone https://github.com/linuxacademy/robot-shop.git  # get the microservice test app

kubectl create namespace robot-shop  # create a name space to isolate the app in the namespace
kubectl -n robot-shop create -f ~/robot-shop/K8s/descriptors/			# run all deployments and services


kubectl get pods -n robot-shop -w     # -w option to watch the status of the pods

http://$kube_server_public_ip:30080		# and just like that the app is running

-----------------------------------------------------------------------------------------------------------------
# Deleting Resources
# delete all
kubectl -n my-ns delete pod --all
kubectl -n my-ns delete svc --all 
kubectl -n my-ns delete deployment --all 
kubectl -n my-ns delete pod,svc,deployment --all 



kubectl get pods -A
kubectl get nodes -o wide
